{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "787a5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda import get_objectives, get_constraints, non_dominated_sort, non_dominated, assign_crowding_distance, binary_tournament_selection, sample_population, cleanupsamples, generate_example_data, organize_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a453b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "import numpy as np\n",
    "from scipy.stats import gamma, norm\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from numba import jit\n",
    "import math\n",
    "from hdf5storage import loadmat, savemat\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c31fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_items_to_z(items):\n",
    "    alpha = np.empty(items.shape[1])\n",
    "    beta = np.empty(items.shape[1])\n",
    "    items_z = np.empty(items.shape)\n",
    "    items_r = items + 1\n",
    "    for i in range(items_r.shape[1]):\n",
    "        a, loc, scale = gamma.fit(items_r[:, i], floc=0.0)\n",
    "        alpha[i] = a\n",
    "        beta[i] = scale\n",
    "        u = gamma.cdf(items_r[:,i], a = a, scale = scale)\n",
    "        u = np.clip(u, 1e-12, 1-1e-12)\n",
    "        items_z[:,i] = norm.ppf(u) \n",
    "    return alpha, beta, items_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78840ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gamma_y_to_z(YY, XX_z):\n",
    "    N, T, d = YY.shape\n",
    "    YY_z = np.empty((N, T, d), dtype=float)\n",
    "    YY_z[:, 0, :] = XX_z[:, 0, :] \n",
    "    shape = np.full((T-1, d), np.nan)\n",
    "    location = np.full((T-1, d), np.nan)\n",
    "    scale = np.full((T-1, d), np.nan)\n",
    "    for t in range(1, T):\n",
    "        for i in range(d):\n",
    "            y = YY[:, t, i]\n",
    "            y_r = y + 1\n",
    "\n",
    "            if np.ptp(y_r) < 1e-12:\n",
    "                raise RuntimeError(\n",
    "                    f\"Gamma degenerate at t={t}, i={i}\\n\"\n",
    "                    f\"unique(y_r)={np.unique(y_r)}\\n\"\n",
    "                    f\"min={y_r.min()}, max={y_r.max()}\\n\"\n",
    "                    f\"population size={YY.shape[0]}\"\n",
    "                    f\"XX_z= {XX_z[:,t,i]}\"\n",
    "                )\n",
    "\n",
    "            a, loc, b = gamma.fit(y_r, floc=0.0)\n",
    "            u = gamma.cdf(y_r, a=a, loc=loc, scale=b)\n",
    "            u = np.clip(u, 1e-12, 1 - 1e-12)\n",
    "            YY_z[:, t, i] = norm.ppf(u)\n",
    "            shape[t-1, i] = a\n",
    "            location[t-1, i] = loc\n",
    "            scale[t-1, i] = b\n",
    "    return YY_z, shape, location, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4338e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_cumu_objectives(items, items_z, population, n_selected, n_obj, n_con, rng, if_initial):  # can modify to use objectives instead of population\n",
    "    XX = np.empty((population.shape[0], n_selected, n_obj+n_con))\n",
    "    XX_z = np.empty((population.shape[0], n_selected, n_obj+n_con))\n",
    "    for k in range(population.shape[0]):\n",
    "        if if_initial:\n",
    "            qx = rng.permutation(population[k, :]) # permutation only for initial population\n",
    "        else:\n",
    "            qx = population[k, :]\n",
    "        XX[k,:,:] = items[qx,:]\n",
    "        XX_z[k,:,:] = items_z[qx,:]\n",
    "    YY = np.cumsum(XX, axis = 1)\n",
    "    YY_z, shape, location, scale = fit_gamma_y_to_z(YY, XX_z)\n",
    "    return XX, XX_z, YY, YY_z, shape, location, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e1d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_markov_in_y_by_t(X, Y):\n",
    "    K, N, d = X.shape\n",
    "    A_list = np.zeros((N-1, d, d))\n",
    "    b_list = np.zeros((N-1, d))\n",
    "    Q_list = np.zeros((N-1, d, d))\n",
    "    R2_list = np.zeros(N-1)\n",
    "    reg_list = []\n",
    "\n",
    "    for t in range(1, N):  \n",
    "        S_t = Y[:, t-1, :]  \n",
    "        Z_t = X[:, t,   :] \n",
    "\n",
    "        reg_t = LinearRegression(fit_intercept=True)\n",
    "        reg_t.fit(S_t, Z_t)\n",
    "        A_t = reg_t.coef_      # (d, d)\n",
    "        b_t = reg_t.intercept_ # (d,)\n",
    "        Z_hat_t = reg_t.predict(S_t)\n",
    "        R_t = Z_t - Z_hat_t\n",
    "        Q_t = np.cov(R_t, rowvar=False, bias=False)\n",
    "        r2 = reg_t.score(S_t, Z_t)\n",
    "\n",
    "        A_list[t-1, :, :] = A_t\n",
    "        b_list[t-1, :] = b_t\n",
    "        Q_list[t-1, :, :] = Q_t\n",
    "        R2_list[t-1] = r2\n",
    "        reg_list.append(reg_t)\n",
    "    params = {\"A\": A_list,\"b\": b_list,\"Q\": Q_list,\"regs\": reg_list,\"R2\": R2_list}\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1079a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_conditional(items, items_z, population, n_selected, n_obj, n_con, rng, if_initial):\n",
    "    objectives, objectives_z, cumu_objectives, cumu_objectives_z, shape, location, scale = get_norm_cumu_objectives(items, items_z, population, \n",
    "                                                                                                                        n_selected, n_obj, n_con, \n",
    "                                                                                                                        rng, if_initial)\n",
    "    dist_params = fit_markov_in_y_by_t(objectives_z, cumu_objectives_z)\n",
    "    return objectives_z, dist_params, shape, location, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d01cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_density_given_Y_and_t(X_candidates, y_normal, params_time, t):\n",
    "    A_all = params_time[\"A\"]  \n",
    "    b_all = params_time[\"b\"]  \n",
    "    Q_all = params_time[\"Q\"]  \n",
    "\n",
    "    A_t = A_all[t-1]\n",
    "    b_t = b_all[t-1]\n",
    "    Q_t = Q_all[t-1]\n",
    "    X_candidates = np.asarray(X_candidates)\n",
    "    y_normal = np.asarray(y_normal).reshape(-1)\n",
    "    mean_t = A_t @ y_normal + b_t\n",
    "    Q_t = Q_t + 1e-3 * np.eye(Q_t.shape[0])\n",
    "    \n",
    "    densities = mvn.pdf(X_candidates, mean=mean_t, cov=Q_t)\n",
    "    return densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e971a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_rate_model(items_z, XX_0):\n",
    "    mean0 = np.mean(XX_0, axis = 0)\n",
    "    Sigma0 = np.cov(XX_0.T) \n",
    "    # add regularization to diagonal for singularity\n",
    "    Sigma0 = Sigma0 + 1e-3 * np.eye(Sigma0.shape[0])\n",
    "    mvn0 = mvn(mean=mean0, cov=Sigma0)\n",
    "    x_candidates = items_z\n",
    "    probabilities = mvn0.pdf(x_candidates)\n",
    "    probabilities = (probabilities+1e-12)/sum(probabilities+1e-12)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af21c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_population_conditional(\n",
    "    samples, samples_z, objectives_z, dist_params,\n",
    "    shape, location, scale, if_converged,\n",
    "    pop_size, n_selected, n_obj, n_con, capacity, rng):\n",
    "\n",
    "    pop_count = 0\n",
    "    population = np.zeros((pop_size, n_selected), dtype=np.int32)\n",
    "    n_items = samples.shape[0]\n",
    "\n",
    "    while pop_count < pop_size:\n",
    "        knapsack_indices = np.zeros(n_selected, dtype=int)    \n",
    "        knapsack = np.zeros((n_selected,(n_obj+n_con)))\n",
    "\n",
    "        probabilities = np.ones(n_items) / n_items # sample first item from uniform\n",
    "        first_choice = rng.choice(n_items, p=probabilities)\n",
    "        knapsack_indices[0] = first_choice\n",
    "        knapsack[0, :] = samples[first_choice, :]\n",
    "        y_prev_z = samples_z[first_choice, :] \n",
    "        y_cum = knapsack[0, :].copy()\n",
    "\n",
    "        for n in range(1, n_selected):\n",
    "            x_indices = np.setdiff1d(np.arange(n_items), knapsack_indices[:n])   \n",
    "            x_candidates = samples_z[x_indices, :] \n",
    "            densities = conditional_density_given_Y_and_t(x_candidates, y_prev_z, dist_params, n)\n",
    "            probabilities = densities/sum(densities)\n",
    "            \n",
    "            next_choice = rng.choice(len(probabilities), p=probabilities)\n",
    "            next_index = x_indices[next_choice]\n",
    "            knapsack_indices[n] = next_index\n",
    "            knapsack[n, :] = samples[next_index, :]\n",
    "            \n",
    "            # normalize y\n",
    "            y_cum += knapsack[n, :]\n",
    "            u = gamma.cdf(y_cum, a=shape[n-1, :], loc=location[n-1, :], scale=scale[n-1, :])\n",
    "            u = np.clip(u, 1e-12, 1-1e-12)\n",
    "            y_prev_z = norm.ppf(u)\n",
    "        \n",
    "        constraint = np.sum(samples[knapsack_indices, -1])\n",
    "        if constraint <= capacity:\n",
    "            population[pop_count, :] = knapsack_indices\n",
    "            pop_count += 1\n",
    "    \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ca8b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_population_conditional_converged(\n",
    "    samples, samples_z, objectives_z, dist_params,\n",
    "    shape, location, scale, if_converged,\n",
    "    pop_size, n_selected, n_obj, n_con, capacity, rng):\n",
    "\n",
    "    pop_count = 0\n",
    "    population = np.zeros((pop_size, n_selected), dtype=np.int32)\n",
    "    n_items = samples.shape[0]\n",
    "\n",
    "    while pop_count < pop_size:\n",
    "        knapsack_indices = np.zeros(n_selected, dtype=int)    \n",
    "        knapsack = np.zeros((n_selected,(n_obj+n_con)))\n",
    "\n",
    "        probabilities = base_rate_model(samples_z, objectives_z[:, 0, :]) # sample first item from base rate model\n",
    "        first_choice = rng.choice(n_items, p=probabilities)\n",
    "        knapsack_indices[0] = first_choice\n",
    "        knapsack[0, :] = samples[first_choice, :]\n",
    "        y_prev_z = samples_z[first_choice, :] \n",
    "        y_cum = knapsack[0, :].copy()\n",
    "\n",
    "        for n in range(1, n_selected):\n",
    "            x_indices = np.setdiff1d(np.arange(n_items), knapsack_indices[:n])   \n",
    "            x_candidates = samples_z[x_indices, :] \n",
    "            densities = conditional_density_given_Y_and_t(x_candidates, y_prev_z, dist_params, n)\n",
    "            probabilities = densities/sum(densities)\n",
    "            \n",
    "            next_choice = rng.choice(len(probabilities), p=probabilities)\n",
    "            next_index = x_indices[next_choice]\n",
    "            knapsack_indices[n] = next_index\n",
    "            knapsack[n, :] = samples[next_index, :]\n",
    "            \n",
    "            # normalize y\n",
    "            y_cum += knapsack[n, :]\n",
    "            u = gamma.cdf(y_cum, a=shape[n-1, :], loc=location[n-1, :], scale=scale[n-1, :])\n",
    "            u = np.clip(u, 1e-12, 1-1e-12)\n",
    "            y_prev_z = norm.ppf(u)\n",
    "        \n",
    "        constraint = np.sum(samples[knapsack_indices, -1])\n",
    "        if constraint <= capacity:\n",
    "            population[pop_count, :] = knapsack_indices\n",
    "            pop_count += 1\n",
    "    \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e14e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnapsackEDACond:\n",
    "    def __init__(self, items, capacity, n_selected, n_obj, n_con, pop_size=1000, \n",
    "                 generations=10, max_no_improve_gen=10, max_iters=100, seed=1123):\n",
    "        self.items = items\n",
    "        self.capacity = capacity\n",
    "        self.n_selected = n_selected\n",
    "        self.n_obj = n_obj\n",
    "        self.n_con = n_con\n",
    "        self.pop_size = pop_size\n",
    "        self.generations = generations\n",
    "        self.max_no_improve_gen = max_no_improve_gen\n",
    "        self.max_iters = max_iters\n",
    "        self.rng = random.default_rng(seed=seed)\n",
    "\n",
    "        self.items_z = None\n",
    "        # self.ecdf_table = None\n",
    "        self.shape = None\n",
    "        self.location = None\n",
    "        self.scale = None\n",
    "        self.if_initial = True\n",
    "        self.if_converged = False\n",
    "\n",
    "        self.first_item_dist = None\n",
    "        self.distribution_params = None\n",
    "        self.selected_population = None  # (pop_size, n_selected)\n",
    "        self.selected_objectives = None  # (pop_size, n_obj) objective values are summed over solutions\n",
    "        self.objectives_z = None  # (pop_size, n_selected, n_obj)\n",
    "\n",
    "        self.distribution_params_table = []\n",
    "        self.pareto_indices_table = []\n",
    "        self.pareto_front_table = []\n",
    "        self.js_div_list = []\n",
    "        self.converged_pf_table = []\n",
    "        self.selected_objectives_table = []\n",
    "\n",
    "    def _generate_initial_population(self):\n",
    "        n_items = self.items.shape[0]\n",
    "        distribution = np.ones(n_items) / n_items\n",
    "        population = sample_population(\n",
    "            self.items, distribution, self.pop_size, self.n_selected, \n",
    "            self.capacity, self.rng\n",
    "        )\n",
    "        objectives = get_objectives(self.items, population, self.n_obj)\n",
    "        \n",
    "        ranks, fronts = non_dominated_sort(objectives)\n",
    "        distances_all_solutions = np.zeros(population.shape[0], dtype=float)\n",
    "        for f in fronts:\n",
    "            distances = assign_crowding_distance(objectives[f, :])\n",
    "            distances_all_solutions[f] = distances\n",
    "\n",
    "        select_indices = np.array([], dtype=int)\n",
    "        while len(select_indices) < self.pop_size:\n",
    "            indice = binary_tournament_selection(\n",
    "                population, ranks, distances_all_solutions, self.rng\n",
    "            )\n",
    "            select_indices = np.concatenate([select_indices, np.array([indice])])\n",
    "        \n",
    "        selected_population = population[select_indices]\n",
    "        selected_objectives = objectives[select_indices]\n",
    "\n",
    "        _, _, self.items_z = transform_items_to_z(self.items)\n",
    "        self.objectives_z, self.distribution_params, self.shape, self.location, self.scale = fit_conditional(self.items, self.items_z, selected_population, \n",
    "                                                                                                                self.n_selected, self.n_obj, self.n_con,\n",
    "                                                                                                                self.rng, self.if_initial) # may need a different rng\n",
    "        self.first_item_dist = base_rate_model(self.items_z, self.objectives_z[:, 0, :])\n",
    "        self.selected_population = selected_population\n",
    "        self.selected_objectives = selected_objectives\n",
    "\n",
    "    def _update_distribution(self):\n",
    "        # sampling\n",
    "        population = sample_population_conditional(\n",
    "            self.items, self.items_z, self.objectives_z, self.distribution_params,\n",
    "            self.shape, self.location, self.scale, self.if_converged,\n",
    "            self.pop_size, self.n_selected, self.n_obj, self.n_con, self.capacity, self.rng\n",
    "        )\n",
    "        objectives = get_objectives(self.items, population, self.n_obj)\n",
    "        \n",
    "        # find current pareto front\n",
    "        _, fronts_current = non_dominated_sort(objectives)\n",
    "        pareto_indices = population[fronts_current[0]]\n",
    "        \n",
    "        # stack populations\n",
    "        objectives = np.vstack((self.selected_objectives, objectives))\n",
    "        population = np.vstack((self.selected_population, population))\n",
    "        \n",
    "        # select through non-dominated sorting\n",
    "        ranks, fronts = non_dominated_sort(objectives)\n",
    "        select_indices = np.array([], dtype=np.int32)\n",
    "        for f in fronts:\n",
    "            if len(select_indices) + len(f) <= self.pop_size:\n",
    "                select_indices = np.concatenate([select_indices, f])\n",
    "            else:\n",
    "                remaining_size = self.pop_size - len(select_indices)\n",
    "                f_distance = assign_crowding_distance(objectives[f, :])\n",
    "                sort_indices = np.argsort(f_distance)[::-1]\n",
    "                remaining = f[sort_indices[:remaining_size]]\n",
    "                select_indices = np.concatenate([select_indices, remaining])\n",
    "                break\n",
    "        selected_population = population[select_indices]\n",
    "        selected_objectives = objectives[select_indices]\n",
    "        \n",
    "        # determine training population\n",
    "        # if self.if_converged:\n",
    "        #     training_population = population[fronts[0]]\n",
    "        # else:\n",
    "        n_training = int(self.pop_size*0.15)\n",
    "        training_population = selected_population[:n_training]\n",
    "        \n",
    "        # update distribution\n",
    "        self.objectives_z, self.distribution_params, self.shape, self.location, self.scale= fit_conditional(self.items, self.items_z, training_population, \n",
    "                                                                                                                self.n_selected, self.n_obj, self.n_con,\n",
    "                                                                                                                self.rng, self.if_initial)\n",
    "        \n",
    "        self.selected_population = selected_population\n",
    "        self.selected_objectives = selected_objectives\n",
    "\n",
    "        # compute js divergence\n",
    "        updated_first_item_dist = base_rate_model(self.items_z, self.objectives_z[:, 0, :])\n",
    "        self.first_item_dist[self.first_item_dist < 1E-08] = 1E-08\n",
    "        updated_first_item_dist[updated_first_item_dist < 1E-08] = 1E-08\n",
    "        js_div = jensenshannon(self.first_item_dist, updated_first_item_dist)**2\n",
    "        self.first_item_dist = updated_first_item_dist\n",
    "        \n",
    "        return pareto_indices, js_div\n",
    "\n",
    "    def _converged_pf(self):\n",
    "        # sampling\n",
    "        population = sample_population_conditional_converged(\n",
    "            self.items, self.items_z, self.objectives_z, self.distribution_params,\n",
    "            self.shape, self.location, self.scale, self.if_converged,\n",
    "            self.pop_size, self.n_selected, self.n_obj, self.n_con, self.capacity, self.rng)\n",
    "        objectives = get_objectives(self.items, population, self.n_obj)\n",
    "\n",
    "        # find current pareto front\n",
    "        pareto_indices = population[non_dominated(objectives).astype(bool)]\n",
    "        \n",
    "        # stack populations\n",
    "        population = np.unique(np.sort(np.vstack((self.selected_population, population)), axis=1), axis=0)\n",
    "        objectives = get_objectives(self.items, population, self.n_obj)\n",
    "\n",
    "        # select through non-dominated\n",
    "        nd_idx = non_dominated(objectives).astype(bool)\n",
    "        selected_population = population[nd_idx]\n",
    "        selected_objectives = objectives[nd_idx]\n",
    "\n",
    "        # update distribution\n",
    "        self.objectives_z, self.distribution_params, self.shape, self.location, self.scale = fit_conditional(self.items, self.items_z, selected_population, \n",
    "                                                                                                                self.n_selected, self.n_obj, self.n_con,\n",
    "                                                                                                                self.rng, self.if_initial)\n",
    "        self.selected_population = selected_population\n",
    "        self.selected_objectives = selected_objectives    \n",
    "\n",
    "        # compute js divergence\n",
    "        updated_first_item_dist = base_rate_model(self.items_z, self.objectives_z[:, 0, :])\n",
    "        self.first_item_dist[self.first_item_dist < 1E-08] = 1E-08\n",
    "        updated_first_item_dist[updated_first_item_dist < 1E-08] = 1E-08\n",
    "        js_div = jensenshannon(self.first_item_dist, updated_first_item_dist)**2\n",
    "        self.first_item_dist = updated_first_item_dist                                                                         \n",
    "        \n",
    "        return pareto_indices, js_div\n",
    "\n",
    "    def run(self):\n",
    "        self._generate_initial_population()\n",
    "        self.if_initial = False\n",
    "        \n",
    "        # Run generations (fixed number of generations)\n",
    "        # for g in range(self.generations):\n",
    "        #     print(f\"Generation {g+1}/{self.generations}\")\n",
    "        #     pareto_indices, js_div = self._update_distribution()\n",
    "        #     print(f\"number of front 0: {pareto_indices.shape[0]}\")\n",
    "            \n",
    "        #     pareto_front = np.zeros((pareto_indices.shape[0], self.items.shape[1]))\n",
    "        #     for k in range(pareto_indices.shape[0]):\n",
    "        #         pareto_front[k, :] = np.sum(self.items[pareto_indices[k, :], :], axis=0)\n",
    "                \n",
    "        #     self.distribution_params_table.append(self.distribution_params.copy())\n",
    "        #     self.pareto_indices_table.append(pareto_indices.copy())\n",
    "        #     self.pareto_front_table.append(pareto_front.copy())\n",
    "        #     self.js_div_list.append(js_div)\n",
    "\n",
    "        # return {\n",
    "        #     'distribution_params_table': self.distribution_params_table,\n",
    "        #     'pareto_indices_table': self.pareto_indices_table,\n",
    "        #     'pareto_front_table': self.pareto_front_table,\n",
    "        #     'js_div_list': self.js_div_list,\n",
    "        #     'objectives_z': self.objectives_z,\n",
    "        #     'items_z': self.items_z,\n",
    "        #     'shape': self.shape,\n",
    "        #     'location': self.location,\n",
    "        #     'scale': self.scale\n",
    "        # }\n",
    "        \n",
    "        # # Run generations (until convergence)\n",
    "        # part 1: train on a portion of selected population till base rate converges\n",
    "        no_improve_gen = 0\n",
    "        prev_js_div = None\n",
    "        generation = 0\n",
    "        min_gens = 30\n",
    "        while no_improve_gen < self.max_no_improve_gen:\n",
    "        # for generation in range(self.generations):\n",
    "            generation += 1\n",
    "            print(f\"Generation {generation} (no improve count: {no_improve_gen})\")\n",
    "            pareto_indices, js_div = self._update_distribution()\n",
    "            print(f\"number of front 0: {pareto_indices.shape[0]}\")\n",
    "\n",
    "            pareto_front = np.zeros((pareto_indices.shape[0], self.items.shape[1]))\n",
    "            for k in range(pareto_indices.shape[0]):\n",
    "                pareto_front[k, :] = np.sum(self.items[pareto_indices[k, :], :], axis=0)\n",
    "                \n",
    "            self.distribution_params_table.append(self.distribution_params.copy())\n",
    "            self.pareto_indices_table.append(pareto_indices.copy())\n",
    "            self.pareto_front_table.append(pareto_front.copy())\n",
    "            self.js_div_list.append(js_div)\n",
    "            self.selected_objectives_table.append(self.selected_objectives.copy())\n",
    "                \n",
    "            # option 1\n",
    "            if prev_js_div is not None:\n",
    "                diff = prev_js_div - js_div\n",
    "                if generation > min_gens and np.abs(diff) < 0.005: # criteria may change\n",
    "                # if np.abs(diff) < 0.005:\n",
    "                    no_improve_gen += 1\n",
    "                else:\n",
    "                    no_improve_gen = 0\n",
    "            else:\n",
    "                no_improve_gen = 0\n",
    "            ## option2\n",
    "            # if js_div < 0.005:\n",
    "            #     no_improve_gen += 1\n",
    "            # else:\n",
    "            #     no_improve_gen = 0\n",
    "            prev_js_div = js_div\n",
    "        \n",
    "        # part 2: train on only the non-dominated solutions till pareto front converges\n",
    "        no_improve_gen = 0\n",
    "        counter = 0\n",
    "        prev_front_0 = None\n",
    "        while no_improve_gen < self.max_no_improve_gen and counter < self.max_iters:\n",
    "            counter += 1\n",
    "            print(f\"Iterations {counter} (no improve count: {no_improve_gen})\")\n",
    "            pareto_indices, js_div = self._converged_pf()\n",
    "            print(f\"number of front 0: {pareto_indices.shape[0]}\")\n",
    "\n",
    "            pareto_front = np.zeros((pareto_indices.shape[0], self.items.shape[1]))\n",
    "            for k in range(pareto_indices.shape[0]):\n",
    "                pareto_front[k, :] = np.sum(self.items[pareto_indices[k, :], :], axis=0)\n",
    "\n",
    "            self.distribution_params_table.append(self.distribution_params.copy())\n",
    "            self.pareto_indices_table.append(pareto_indices.copy())\n",
    "            self.pareto_front_table.append(pareto_front.copy())\n",
    "            self.js_div_list.append(js_div)\n",
    "            self.selected_objectives_table.append(self.selected_objectives.copy())\n",
    "            \n",
    "            front_0 = np.unique(self.selected_objectives, axis=0)\n",
    "            # front_0 = np.unique(pareto_front, axis=0)\n",
    "            front_0 = front_0[np.lexsort(front_0.T[::-1])]\n",
    "            if prev_front_0 is not None:\n",
    "                if np.array_equal(prev_front_0, front_0):\n",
    "                    no_improve_gen += 1\n",
    "                else:\n",
    "                    no_improve_gen = 0\n",
    "            else:\n",
    "                no_improve_gen = 0\n",
    "            \n",
    "            self.converged_pf_table.append(front_0.copy())\n",
    "            prev_front_0 = front_0\n",
    "\n",
    "\n",
    "        return {\n",
    "            'distribution_params_table': self.distribution_params_table,\n",
    "            'pareto_indices_table': self.pareto_indices_table,\n",
    "            'pareto_front_table': self.pareto_front_table,\n",
    "            'converged_pf_table': self.converged_pf_table,\n",
    "            'js_div_list': self.js_div_list,\n",
    "            'objectives_z': self.objectives_z,\n",
    "            'items_z': self.items_z,\n",
    "            'shape': self.shape,\n",
    "            'location': self.location,\n",
    "            'scale': self.scale,\n",
    "            'base_rate_dist': self.first_item_dist,\n",
    "            'selected_objectives_table': self.selected_objectives_table\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd49d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = loadmat('/home/tailai/data/knapsack/runB/kn_1_3_allneg_60_6_3.mat')\n",
    "items = kn['items'][4]\n",
    "shape = kn['shape']\n",
    "scale = kn['scale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb7ce57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "eda_seed = 1223\n",
    "n_items = 60\n",
    "n_selected = 6\n",
    "n_obj = 3\n",
    "n_con = 1\n",
    "capacity = int(shape[-1]*scale[-1]*n_selected)\n",
    "pop_size = 1000\n",
    "generations = 100 # do not matter if check convergence\n",
    "max_no_improve_gen = 5\n",
    "max_iters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "794042ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 (no improve count: 0)\n",
      "number of front 0: 37\n",
      "Generation 2 (no improve count: 0)\n",
      "number of front 0: 43\n",
      "Generation 3 (no improve count: 0)\n",
      "number of front 0: 55\n",
      "Generation 4 (no improve count: 0)\n",
      "number of front 0: 54\n",
      "Generation 5 (no improve count: 0)\n",
      "number of front 0: 47\n",
      "Generation 6 (no improve count: 0)\n",
      "number of front 0: 48\n",
      "Generation 7 (no improve count: 0)\n",
      "number of front 0: 40\n",
      "Generation 8 (no improve count: 0)\n",
      "number of front 0: 46\n",
      "Generation 9 (no improve count: 0)\n",
      "number of front 0: 45\n",
      "Generation 10 (no improve count: 0)\n",
      "number of front 0: 56\n",
      "Generation 11 (no improve count: 0)\n",
      "number of front 0: 52\n",
      "Generation 12 (no improve count: 0)\n",
      "number of front 0: 80\n",
      "Generation 13 (no improve count: 0)\n",
      "number of front 0: 136\n",
      "Generation 14 (no improve count: 0)\n",
      "number of front 0: 224\n",
      "Generation 15 (no improve count: 0)\n",
      "number of front 0: 301\n",
      "Generation 16 (no improve count: 0)\n",
      "number of front 0: 291\n",
      "Generation 17 (no improve count: 0)\n",
      "number of front 0: 281\n",
      "Generation 18 (no improve count: 0)\n",
      "number of front 0: 256\n",
      "Generation 19 (no improve count: 0)\n",
      "number of front 0: 264\n",
      "Generation 20 (no improve count: 0)\n",
      "number of front 0: 284\n",
      "Generation 21 (no improve count: 0)\n",
      "number of front 0: 258\n",
      "Generation 22 (no improve count: 0)\n",
      "number of front 0: 276\n",
      "Generation 23 (no improve count: 0)\n",
      "number of front 0: 279\n",
      "Generation 24 (no improve count: 0)\n",
      "number of front 0: 256\n",
      "Generation 25 (no improve count: 0)\n",
      "number of front 0: 278\n",
      "Generation 26 (no improve count: 0)\n",
      "number of front 0: 266\n",
      "Generation 27 (no improve count: 0)\n",
      "number of front 0: 277\n",
      "Generation 28 (no improve count: 0)\n",
      "number of front 0: 237\n",
      "Generation 29 (no improve count: 0)\n",
      "number of front 0: 259\n",
      "Generation 30 (no improve count: 0)\n",
      "number of front 0: 272\n",
      "Generation 31 (no improve count: 0)\n",
      "number of front 0: 307\n",
      "Generation 32 (no improve count: 1)\n",
      "number of front 0: 275\n",
      "Generation 33 (no improve count: 2)\n",
      "number of front 0: 254\n",
      "Generation 34 (no improve count: 3)\n",
      "number of front 0: 250\n",
      "Generation 35 (no improve count: 4)\n",
      "number of front 0: 246\n",
      "Iterations 1 (no improve count: 0)\n",
      "number of front 0: 270\n",
      "Iterations 2 (no improve count: 0)\n",
      "number of front 0: 363\n",
      "Iterations 3 (no improve count: 0)\n",
      "number of front 0: 278\n",
      "Iterations 4 (no improve count: 0)\n",
      "number of front 0: 283\n",
      "Iterations 5 (no improve count: 0)\n",
      "number of front 0: 291\n",
      "Iterations 6 (no improve count: 0)\n",
      "number of front 0: 293\n",
      "Iterations 7 (no improve count: 0)\n",
      "number of front 0: 297\n",
      "Iterations 8 (no improve count: 0)\n",
      "number of front 0: 356\n",
      "Iterations 9 (no improve count: 0)\n",
      "number of front 0: 312\n",
      "Iterations 10 (no improve count: 0)\n",
      "number of front 0: 322\n",
      "Iterations 11 (no improve count: 0)\n",
      "number of front 0: 391\n",
      "Iterations 12 (no improve count: 0)\n",
      "number of front 0: 294\n",
      "Iterations 13 (no improve count: 0)\n",
      "number of front 0: 309\n",
      "Iterations 14 (no improve count: 1)\n",
      "number of front 0: 307\n",
      "Iterations 15 (no improve count: 2)\n",
      "number of front 0: 324\n",
      "Iterations 16 (no improve count: 0)\n",
      "number of front 0: 287\n",
      "Iterations 17 (no improve count: 0)\n",
      "number of front 0: 328\n",
      "Iterations 18 (no improve count: 1)\n",
      "number of front 0: 280\n",
      "Iterations 19 (no improve count: 2)\n",
      "number of front 0: 345\n",
      "Iterations 20 (no improve count: 0)\n",
      "number of front 0: 292\n",
      "Iterations 21 (no improve count: 0)\n",
      "number of front 0: 291\n",
      "Iterations 22 (no improve count: 1)\n",
      "number of front 0: 286\n",
      "Iterations 23 (no improve count: 0)\n",
      "number of front 0: 360\n",
      "Iterations 24 (no improve count: 0)\n",
      "number of front 0: 285\n",
      "Iterations 25 (no improve count: 1)\n",
      "number of front 0: 314\n",
      "Iterations 26 (no improve count: 0)\n",
      "number of front 0: 254\n",
      "Iterations 27 (no improve count: 0)\n",
      "number of front 0: 300\n",
      "Iterations 28 (no improve count: 0)\n",
      "number of front 0: 250\n",
      "Iterations 29 (no improve count: 0)\n",
      "number of front 0: 239\n",
      "Iterations 30 (no improve count: 0)\n",
      "number of front 0: 232\n",
      "Iterations 31 (no improve count: 0)\n",
      "number of front 0: 239\n",
      "Iterations 32 (no improve count: 0)\n",
      "number of front 0: 267\n",
      "Iterations 33 (no improve count: 0)\n",
      "number of front 0: 220\n",
      "Iterations 34 (no improve count: 0)\n",
      "number of front 0: 225\n",
      "Iterations 35 (no improve count: 1)\n",
      "number of front 0: 243\n",
      "Iterations 36 (no improve count: 0)\n",
      "number of front 0: 266\n",
      "Iterations 37 (no improve count: 0)\n",
      "number of front 0: 283\n",
      "Iterations 38 (no improve count: 0)\n",
      "number of front 0: 246\n",
      "Iterations 39 (no improve count: 0)\n",
      "number of front 0: 228\n",
      "Iterations 40 (no improve count: 0)\n",
      "number of front 0: 247\n",
      "Iterations 41 (no improve count: 0)\n",
      "number of front 0: 246\n",
      "Iterations 42 (no improve count: 0)\n",
      "number of front 0: 215\n",
      "Iterations 43 (no improve count: 0)\n",
      "number of front 0: 274\n",
      "Iterations 44 (no improve count: 0)\n",
      "number of front 0: 269\n",
      "Iterations 45 (no improve count: 1)\n",
      "number of front 0: 300\n",
      "Iterations 46 (no improve count: 0)\n",
      "number of front 0: 284\n",
      "Iterations 47 (no improve count: 0)\n",
      "number of front 0: 285\n",
      "Iterations 48 (no improve count: 0)\n",
      "number of front 0: 249\n",
      "Iterations 49 (no improve count: 0)\n",
      "number of front 0: 274\n",
      "Iterations 50 (no improve count: 1)\n",
      "number of front 0: 299\n",
      "Iterations 51 (no improve count: 0)\n",
      "number of front 0: 292\n",
      "Iterations 52 (no improve count: 0)\n",
      "number of front 0: 292\n",
      "Iterations 53 (no improve count: 0)\n",
      "number of front 0: 252\n",
      "Iterations 54 (no improve count: 1)\n",
      "number of front 0: 270\n",
      "Iterations 55 (no improve count: 0)\n",
      "number of front 0: 254\n",
      "Iterations 56 (no improve count: 0)\n",
      "number of front 0: 282\n",
      "Iterations 57 (no improve count: 1)\n",
      "number of front 0: 302\n",
      "Iterations 58 (no improve count: 0)\n",
      "number of front 0: 265\n",
      "Iterations 59 (no improve count: 0)\n",
      "number of front 0: 312\n",
      "Iterations 60 (no improve count: 0)\n",
      "number of front 0: 310\n",
      "Iterations 61 (no improve count: 0)\n",
      "number of front 0: 315\n",
      "Iterations 62 (no improve count: 0)\n",
      "number of front 0: 326\n",
      "Iterations 63 (no improve count: 1)\n",
      "number of front 0: 305\n",
      "Iterations 64 (no improve count: 0)\n",
      "number of front 0: 294\n",
      "Iterations 65 (no improve count: 0)\n",
      "number of front 0: 305\n",
      "Iterations 66 (no improve count: 0)\n",
      "number of front 0: 329\n",
      "Iterations 67 (no improve count: 0)\n",
      "number of front 0: 323\n",
      "Iterations 68 (no improve count: 0)\n",
      "number of front 0: 321\n",
      "Iterations 69 (no improve count: 1)\n",
      "number of front 0: 297\n",
      "Iterations 70 (no improve count: 0)\n",
      "number of front 0: 323\n",
      "Iterations 71 (no improve count: 0)\n",
      "number of front 0: 321\n",
      "Iterations 72 (no improve count: 1)\n",
      "number of front 0: 288\n",
      "Iterations 73 (no improve count: 0)\n",
      "number of front 0: 321\n",
      "Iterations 74 (no improve count: 1)\n",
      "number of front 0: 290\n",
      "Iterations 75 (no improve count: 2)\n",
      "number of front 0: 306\n",
      "Iterations 76 (no improve count: 3)\n",
      "number of front 0: 295\n",
      "Iterations 77 (no improve count: 4)\n",
      "number of front 0: 296\n",
      "Iterations 78 (no improve count: 0)\n",
      "number of front 0: 265\n",
      "Iterations 79 (no improve count: 0)\n",
      "number of front 0: 298\n",
      "Iterations 80 (no improve count: 0)\n",
      "number of front 0: 250\n",
      "Iterations 81 (no improve count: 1)\n",
      "number of front 0: 308\n",
      "Iterations 82 (no improve count: 2)\n",
      "number of front 0: 259\n",
      "Iterations 83 (no improve count: 0)\n",
      "number of front 0: 276\n",
      "Iterations 84 (no improve count: 1)\n",
      "number of front 0: 305\n",
      "Iterations 85 (no improve count: 2)\n",
      "number of front 0: 285\n",
      "Iterations 86 (no improve count: 0)\n",
      "number of front 0: 259\n",
      "Iterations 87 (no improve count: 1)\n",
      "number of front 0: 276\n",
      "Iterations 88 (no improve count: 2)\n",
      "number of front 0: 249\n",
      "Iterations 89 (no improve count: 3)\n",
      "number of front 0: 274\n",
      "Iterations 90 (no improve count: 0)\n",
      "number of front 0: 292\n",
      "Iterations 91 (no improve count: 0)\n",
      "number of front 0: 286\n",
      "Iterations 92 (no improve count: 1)\n",
      "number of front 0: 259\n",
      "Iterations 93 (no improve count: 2)\n",
      "number of front 0: 310\n",
      "Iterations 94 (no improve count: 3)\n",
      "number of front 0: 286\n",
      "Iterations 95 (no improve count: 4)\n",
      "number of front 0: 262\n"
     ]
    }
   ],
   "source": [
    "eda = KnapsackEDACond(\n",
    "    items=items,\n",
    "    capacity=capacity,\n",
    "    n_selected=n_selected,\n",
    "    n_obj=n_obj,\n",
    "    n_con=n_con,\n",
    "    pop_size=pop_size,\n",
    "    generations=generations,\n",
    "    max_no_improve_gen=max_no_improve_gen,\n",
    "    seed=eda_seed\n",
    ")\n",
    "\n",
    "# organize results    \n",
    "results = eda.run()\n",
    "with open('new_results_1_3_obj3_run2.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numba_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
